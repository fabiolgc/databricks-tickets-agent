# Quick Start Guide - Databricks Tickets Agent

## ğŸš€ Resumo RÃ¡pido

Este projeto fornece uma base de dados completa para demonstraÃ§Ã£o de agente GenAI de anÃ¡lise de tickets de suporte ao cliente.

### Arquivos Gerados

```
âœ“ 5 arquivos CSV com dados sintÃ©ticos:
  - companies.csv (100 empresas)
  - customers.csv (300 clientes)
  - agents.csv (25 agentes)
  - tickets.csv (500 tickets)
  - ticket_interactions.csv (2,649 interaÃ§Ãµes)

âœ“ Scripts SQL:
  - ddl_tables.sql (criaÃ§Ã£o das tabelas Delta)
  - load_data.sql (importaÃ§Ã£o dos dados)
  - analysis_queries.sql (queries de anÃ¡lise)

âœ“ CÃ³digo Python:
  - generate_data.py (gerador de dados)
  - genai_agent_example.py (notebook exemplo)
```

## ğŸ“‹ Passo a Passo - 5 Minutos

### 1. Criar as Tabelas (1 min)

No Databricks SQL Editor:

```sql
-- Cole e execute o conteÃºdo de ddl_tables.sql
-- Isso criarÃ¡ 5 tabelas: companies, customers, agents, tickets, ticket_interactions
```

### 2. Upload dos CSVs (2 min)

**OpÃ§Ã£o A - Via Interface do Databricks:**
1. Acesse: Data â†’ Add Data â†’ Upload File
2. FaÃ§a upload de todos os 5 arquivos CSV
3. Anote o caminho onde foram salvos (ex: `/FileStore/tables/`)

**OpÃ§Ã£o B - Via Databricks CLI:**
```bash
databricks fs cp *.csv dbfs:/FileStore/tickets/ --recursive
```

### 3. Carregar os Dados (2 min)

No Databricks SQL Editor, ajuste os caminhos e execute:

```sql
-- Carrega companies
COPY INTO companies
FROM '/FileStore/tickets/companies.csv'  -- Ajuste o caminho!
FILEFORMAT = CSV
FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'false');

-- Carrega agents
COPY INTO agents
FROM '/FileStore/tickets/agents.csv'
FILEFORMAT = CSV
FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'false');

-- Carrega customers
COPY INTO customers
FROM '/FileStore/tickets/customers.csv'
FILEFORMAT = CSV
FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'false');

-- Carrega tickets
COPY INTO tickets
FROM '/FileStore/tickets/tickets.csv'
FILEFORMAT = CSV
FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'false');

-- Carrega interactions
COPY INTO ticket_interactions
FROM '/FileStore/tickets/ticket_interactions.csv'
FILEFORMAT = CSV
FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'false');
```

### 4. Verificar os Dados

```sql
-- Conta registros em cada tabela
SELECT 'companies' AS table_name, COUNT(*) AS records FROM companies
UNION ALL
SELECT 'customers', COUNT(*) FROM customers
UNION ALL
SELECT 'agents', COUNT(*) FROM agents
UNION ALL
SELECT 'tickets', COUNT(*) FROM tickets
UNION ALL
SELECT 'ticket_interactions', COUNT(*) FROM ticket_interactions;
```

Resultado esperado:
- companies: 100
- customers: 300
- agents: 25
- tickets: 500
- ticket_interactions: 2,649

## ğŸ¯ Primeiras Queries - Teste Agora!

### "O que estÃ¡ acontecendo esta semana?"

```sql
SELECT 
    COUNT(*) AS total_tickets,
    COUNT(CASE WHEN status = 'OPEN' THEN 1 END) AS open,
    COUNT(CASE WHEN priority = 'CRITICAL' THEN 1 END) AS critical,
    ROUND(AVG(csat_score), 2) AS avg_satisfaction
FROM tickets
WHERE created_at >= CURRENT_DATE - INTERVAL 7 DAYS;
```

### "Quais sÃ£o os principais problemas?"

```sql
SELECT 
    category,
    subcategory,
    COUNT(*) AS total,
    ROUND(AVG(resolution_time_hours), 2) AS avg_hours
FROM tickets
WHERE created_at >= CURRENT_DATE - INTERVAL 7 DAYS
GROUP BY category, subcategory
ORDER BY total DESC
LIMIT 10;
```

### "Empresas em risco de churn?"

```sql
SELECT 
    c.company_name,
    c.churn_risk_score,
    COUNT(t.ticket_id) AS recent_tickets,
    AVG(t.csat_score) AS satisfaction
FROM companies c
LEFT JOIN tickets t ON c.company_id = t.company_id
WHERE c.churn_risk_score > 0.6
    AND t.created_at >= CURRENT_DATE - INTERVAL 30 DAYS
GROUP BY c.company_name, c.churn_risk_score
ORDER BY c.churn_risk_score DESC;
```

## ğŸ¤– Exemplo de Agente GenAI

Importe o notebook `genai_agent_example.py` no Databricks e execute.

O notebook demonstra:
- âœ… SumarizaÃ§Ã£o inteligente de tickets
- âœ… AnÃ¡lise de tendÃªncias
- âœ… DetecÃ§Ã£o de risco de churn
- âœ… RecomendaÃ§Ã£o de aÃ§Ãµes
- âœ… RelatÃ³rio executivo automatizado

## ğŸ“Š Casos de Uso Demonstrados

### 1. AnÃ¡lise Executiva
"Gere um resumo semanal dos tickets"

### 2. IdentificaÃ§Ã£o de Problemas
"Quais categorias tÃªm mais reclamaÃ§Ãµes?"

### 3. Risco de Churn
"Quais clientes estÃ£o insatisfeitos?"

### 4. Performance do Time
"Como estÃ¡ o desempenho dos agentes?"

### 5. SLA Monitoring
"Quantos tickets violaram o SLA?"

### 6. Next Best Action
"Qual a melhor soluÃ§Ã£o baseada em tickets similares?"

## ğŸ¨ Criando um Dashboard

No Databricks SQL, crie visualizaÃ§Ãµes:

1. **KPIs principais**: Total de tickets, taxa de resoluÃ§Ã£o, CSAT mÃ©dio
2. **GrÃ¡fico de tendÃªncias**: Tickets por dia/semana
3. **DistribuiÃ§Ã£o por categoria**: GrÃ¡fico de pizza
4. **SLA compliance**: GrÃ¡fico de barras por prioridade
5. **Sentiment analysis**: Timeline de sentimentos
6. **Churn risk**: Top 10 empresas em risco

## ğŸ” GovernanÃ§a de Dados (PII)

Os campos marcados como PII nas tabelas:

**companies**: `cnpj`
**customers**: `customer_name`, `email`, `cpf`, `birth_date`, `phone`

Para aplicar mÃ¡scaras no Unity Catalog:

```sql
-- Exemplo: MÃ¡scara de CPF
CREATE FUNCTION mask_cpf(cpf STRING)
RETURNS STRING
RETURN CONCAT('***.', SUBSTRING(cpf, 5, 3), '.', SUBSTRING(cpf, 9, 3), '-**');

-- Aplicar em uma view
CREATE VIEW customers_masked AS
SELECT 
    customer_id,
    customer_name,
    mask_cpf(cpf) as cpf,
    email,
    role
FROM customers;
```

## ğŸš¨ Troubleshooting

### Erro: "Table not found"
- Verifique se executou o `ddl_tables.sql` completo
- Confirme o nome do schema/database correto

### Erro: "File not found"
- Verifique o caminho dos CSVs no DBFS
- Use `%fs ls /FileStore/tickets/` para listar arquivos

### Erro: "Foreign key violation"
- Carregue as tabelas na ordem correta:
  1. companies, agents
  2. customers
  3. tickets
  4. ticket_interactions

### Dados nÃ£o aparecem
- Execute: `REFRESH TABLE nome_da_tabela`
- Verifique se o COPY INTO foi executado com sucesso

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **README.md**: DocumentaÃ§Ã£o completa do projeto
- **analysis_queries.sql**: 50+ queries prontas para anÃ¡lise
- **genai_agent_example.py**: Notebook completo com exemplos

## ğŸ“ PrÃ³ximos Passos

1. âœ… **Dados carregados** â†’ Explore as queries de anÃ¡lise
2. ğŸ¤– **Teste o notebook** â†’ Execute genai_agent_example.py
3. ğŸ“Š **Crie dashboards** â†’ Use Databricks SQL Dashboards
4. ğŸ§  **Implemente AI** â†’ Use AI Functions (ai_summarize, ai_classify)
5. ğŸ” **Vector Search** â†’ Busca semÃ¢ntica de tickets similares
6. ğŸš€ **Deploy Agente** â†’ Databricks Model Serving + Lakehouse Apps

## ğŸ’¡ Dicas para a DemonstraÃ§Ã£o

1. **Comece com o problema**: "Gestor quer saber o que estÃ¡ acontecendo sem ler 500 tickets"
2. **Mostre dados reais**: Tickets em portuguÃªs, contexto de pagamentos
3. **Demonstre IA**: SumarizaÃ§Ã£o, classificaÃ§Ã£o, recomendaÃ§Ãµes
4. **Destaque insights**: Churn risk, SLA breaches, sentiment trends
5. **GovernanÃ§a**: Mostre tags PII e Unity Catalog
6. **Escalabilidade**: Delta Lake, Z-ordering, otimizaÃ§Ãµes

## ğŸ¤ Suporte

Para dÃºvidas sobre este projeto, entre em contato com seu Arquiteto de SoluÃ§Ãµes Databricks.

---

**Tempo total de setup: ~5 minutos** âš¡
**Pronto para demonstrar!** ğŸ¯
